---
title: "Summary"
author: "Valentin"
date: "28 12 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("helpfunctions.r")
library("runjags")
library("coda")
library("rjags")
library("survival")
set.seed(8928612)
```
# Introduction
## Some Data Summary Statistics
### Survival functions
Here I just Plot the survival functions, once for both groups together and once seperated
```{r}
plot(survfit(Surv(value) ~ 1, data = Grub), 
     xlab = "Days", lwd = 3, cex.lab = 2,
     ylab = "Overall survival probability",conf.int = F,col = 2)
plot(survfit(Surv(value) ~ group, data = Grub), 
     xlab = "Days", cex.lab = 2,
     ylab = "Overall survival probability",lwd = 3,
     conf.int = F,col = c(2,3))
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")

pdf("..\\graphics\\Plot1.pdf", width = 7, height = 5)
plot(survfit(Surv(value) ~ 1, data = Grub), 
     xlab = "Days",cex.lab = 2, cex.axis = 1.5,
     ylab = "Overall survival probability",conf.int = F,col = 2, lwd = 3)
dev.off()
pdf("..\\graphics\\Plot2.pdf", width = 7, height = 5)
plot(survfit(Surv(value) ~ group, data = Grub), 
     xlab = "Days", cex.lab = 2,cex.axis = 1.5,
     ylab = "Overall survival probability",lwd = 3,
     conf.int = F,col = c(2,3))
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3), cex = 2,
               title = "Groups")
dev.off()
#first is group 0 second is group 1
Grubis <- read.csv("..\\data\\Grubs_Nematodes.csv")
mean(Grubis$GRUBSIZE)
sd(Grubis$GRUBSIZE)
min(Grub$grubsize)
summary(Grubis$GRUBSIZE)
```
### Median Death times
Median death time for Group treated with SS is higher than it is the for the HB EPNs therefore this indicates, that we should use HB since, then we are faster with the killing process
```{r}
median(Grub$value[Grub$group == 0])
mean(Grub$value[Grub$group == 0] >= 4)
median(Grub$value[Grub$group == 1])
mean(Grub$value[Grub$group == 1] >= 4)

```
Different Models
## Without censored without random effects
### Lognormal
#### Models are calculated
We run a lognormal Model, specified in the files. Keep in Mind the data for Grubsize is already normalized

```{r echo=F}
source("Bayes1_lognormal_jags.R")
```
#### Results 
Just the Plots of the Posterior curves of the Parameters and there summarys

```{r}

summary(lognorm_mcmc)
summary(lognorm)

plot(lognorm)
print(lognorm)
cat("second kind of the plots seen before")
plot(lognorm_mcmc)

```


#### Diagnostics
##### Convergence checks
First Gelman and Rubin and Geweke Plots are created, looks kind of ok in my eyes
```{r}
print("gelman diag")
gelman.diag(lognorm_mcmc, confidence = 0.95)
gelman.plot(lognorm_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(lognorm_mcmc)
geweke.plot(lognorm_mcmc)

# dynamic geweke for single chain
gw <- geweke.plot(lognorm_mcmc)
m <- gw[["z"]][, , 1]
df <- as.data.frame(m)

names(df)<- c("beta0","beta1","beta2", "sigma")
it_ini <- 3000
it_fin <- 5500
df['m'] = c(1:20)/20*(it_fin-it_ini)+it_ini
df2 <- data.frame(m = df$m,                            
                       Z = c(df$beta0, df$beta1, df$beta2, df$sigma),
                       group = c(rep("beta0", nrow(df)),
                                 rep("beta1", nrow(df)),
                                 rep("beta2", nrow(df)),
                                 rep("sigma", nrow(df))))
g3<-ggplot(df2, aes(m, Z, col=group))
g3 + geom_point() + geom_hline(aes(yintercept=2),color="black",linetype="dashed") +
  geom_hline(aes(yintercept=-2),color="black",linetype="dashed")+
  labs(title="Geweke diagnostic for chain 1",y="Z-score",x="First iteration in segment")
```

##### DIC

```{r}
extract.runjags(lognorm, "dic")
```
##### CPO and PPo
I always unluckly wrote PPO instead of CPO so it is the same in this document
 

```{r}
subset_pred <- grepl("ppo\\[", dimnames(lognorm_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_mcmc_rep,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)
#which y are thebiggest
matrix(order(icpo,decreasing = T),ncol = 14, nrow = 10, byrow = T)
#Table 2 
matrix(order(ippo,decreasing = T),ncol = 14, nrow = 10, byrow = T)


LPLM <- mean(log(cpo))
LPLM
#2.) extract the res values 
subset_pred <- grepl("res\\[", dimnames(lognorm_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_mcmc_rep,subset_pred)
#how look the average residuals in the log world?
hist(apply(mcmc_subset,2,mean), breaks = 20)

```

##### PPC and more summary
PPC how often true y in 95% intervall
```{r}
subset_pred <- grepl("y_rep\\[", dimnames(lognorm_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_mcmc_rep,subset_pred)

# # mcmc_subset
# #how often are the values bigger or smallen than the predicted ones
# max(apply(apply(mcmc_subset,1,function(x){x > Grub$value}),2,mean))
# 
# #how do the distribution look like comapred to the origninal one
# summary(mcmc_subset[,1])
# hist(Grub$value)
# hist(mcmc_subset[1,],breaks = 20)

# how extreme are the predicted values compared to the original ones
mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))
```

##### DIC Manual
This is just for comparison to the automatic calculated one. Used later for the interval censored part
```{r}
#3.) Get the DIC running
#https://en.wikipedia.org/wiki/Deviance_information_criterion


subset_pred <- grepl("Deviance", dimnames(lognorm_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_mcmc_rep,subset_pred)
mcmc_subset_dic<- mcmc_subset
md <- mean(mcmc_subset_dic)
#This is the calculation of Pd but somehow it does not work for the random effectmodels for me, probably I have made some mistake, but I cant find it. So I switch to pv instead, https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-dic/ which is also kinda recomended and is the variance of the posterior divided by 2, comes from some chisquare approx. Explaination on the link can be found. First still the implementation of BIC is written down.
a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["tau"] <- mean(get_values(lognorm_mcmc_rep,subset_pred))

pd <- md - (-2 *sum(log(dlnorm(Grub$value,a["beta0"]+a["beta1"]*Grub$grubsize 
                   + a["beta2"]*Grub$group,sqrt(1/a["tau"])))))
pv <- var(mcmc_subset_dic)/2
c(pd,md,pd+md)
c(pv,md,pv+md)

```

##### Plot the Model

```{r}
a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta0"] <- median(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta2"] <- median(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["beta1"] <- median(get_values(lognorm_mcmc_rep,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_mcmc_rep[[1]])[[2]])
a["tau"] <- median(get_values(lognorm_mcmc_rep,subset_pred))


# subset_pred <- grepl("y\\[", dimnames(lognorm_mcmc_rep[[1]])[[2]])
# mcmc_subset_y <- get_values(lognorm_mcmc_rep,subset_pred)

size <- seq(-2,4,length.out = 140)
#group 2 beta 2 is the group
gr1_low <- qlnorm(0.025,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr1_mid <- qlnorm(0.5,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr1_up <- qlnorm(0.975,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr2_low <- qlnorm(0.025,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
gr2_mid <- qlnorm(0.5,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
gr2_up <- qlnorm(0.975,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
# 

# y_sample <- apply(mcmc_subset,2,mean)
# Grub$grubsize, Grub$value
# Grub2$grubsize, y_sample
Grub2 <- Grub
plot(Grub$grubsize, Grub$value,  pch = 19,ylim = c(0,20), col = (Grub$group + 2), lwd = 1.5,
      xlab = "Days", cex.lab = 1.8,
     ylab = "Overall survival probability")
lines(size,gr1_low, col = 2,lty = 2, lwd = 3)
lines(size,gr1_mid, col = 2, lwd = 3)
lines(size,gr1_up, col = 2,lty = 2, lwd = 3)
lines(size,gr2_low, col = 3,lty = 2, lwd = 3)
lines(size,gr2_mid, col = 3, lwd = 3)
lines(size,gr2_up, col = 3, lwd = 3,lty = 2)
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")


pdf("..\\graphics\\Plot3.pdf", width = 7, height = 5)
plot(Grub$grubsize, Grub$value,  pch = 19,ylim = c(0,20), col = (Grub2$group + 2), lwd = 1.5,
      xlab = "Days", cex.lab = 1.4,
     ylab = "Overall survival probability")
lines(size,gr1_low, col = 2,lty = 2, lwd = 3)
lines(size,gr1_mid, col = 2, lwd = 3)
lines(size,gr1_up, col = 2,lty = 2, lwd = 3)
lines(size,gr2_low, col = 3,lty = 2, lwd = 3)
lines(size,gr2_mid, col = 3, lwd = 3)
lines(size,gr2_up, col = 3, lwd = 3,lty = 2)
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")
dev.off()
```
##### Sensitivity
```{r}
source("Bayes1_lognormal_jags_sens.R")

```
The results are really simmular despite the second one has a really bad initilitation
```{r}
lognorm$summaries[,4]
lognorm_sens$summaries[,4]
lognorm_sens2$summaries[,4]
```

### Weibull
#### Models are calculated

```{r  echo=F}
source("Bayes1_Weibull_jags.R")
```

#### Results 

```{r}

summary(weibull_mcmc)
summary(weibull)
plot(weibull)
plot(weibull_mcmc)
```
#### Diagnostics
##### Convergence checks
```{r}
#Model Diagnostik plots
weibull_mcmc <- as.mcmc.list(weibull)

print("gelman diag")
gelman.diag(weibull_mcmc, confidence = 0.95)
gelman.plot(weibull_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(weibull_mcmc)
geweke.plot(weibull_mcmc)
```

##### DIC

```{r}
extract.runjags(weibull, "dic")
```
##### CPO and PPo
CPO or better say the inverse of it
 

```{r}
subset_pred <- grepl("ppo\\[", dimnames(weibull_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_mcmc_rep,subset_pred)

#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)
#which y are thebiggest
matrix(order(icpo,decreasing = T),ncol = 14, nrow = 10, byrow = T)
#Table 2 
matrix(order(ippo,decreasing = T),ncol = 14, nrow = 10, byrow = T)

LPLM <- mean(log(cpo))
LPLM
```

##### PPC and more summary
 
```{r}
subset_pred <- grepl("y_rep\\[", dimnames(weibull_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_mcmc_rep,subset_pred)

# mcmc_subset

#how do the distribution look like comapred to the origninal one
hist(Grub$value)
hist(mcmc_subset[1,],breaks = 20)

# how extreme are the predicted values compared to the original ones
mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

```

##### DIC Manual
Again just for comparison.
```{r}

#calculate md
subset_pred <- grepl("Deviance", dimnames(weibull_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_mcmc_rep,subset_pred)
mcmc_subset_dic<- mcmc_subset
md <- mean(mcmc_subset_dic)
md


subset_pred <- grepl("beta0", dimnames(weibull_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(weibull_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(weibull_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(weibull_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(weibull_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(weibull_mcmc_rep,subset_pred))

subset_pred <- grepl("scale", dimnames(weibull_mcmc_rep[[1]])[[2]])
a["scale"] <- mean(get_values(weibull_mcmc_rep,subset_pred))
a1 <- a
scale <- exp(a1["beta0"]+a1["beta1"]*Grub$grubsize + a1["beta2"]*Grub$group)
#for exampe see weibull_baysian_easy (i know wrong spelling ^^) exp()
shape <- 1/a1["scale"]
pd <- md - -2*sum(dweibull(Grub$value, scale = scale, shape  = shape, log = T))
pd

pv <- var(mcmc_subset_dic)/2


c(pd,md,pd+md)
c(pv,md,pv+md)

```
##### Plot the Model

```{r}
modelstuff <- weibull_mcmc_rep
a <- vector()
subset_pred <- grepl("beta0", dimnames(modelstuff[[1]])[[2]])
a["beta0"] <- median(get_values(modelstuff,subset_pred))

subset_pred <- grepl("beta2", dimnames(modelstuff[[1]])[[2]])
a["beta2"] <- median(get_values(modelstuff,subset_pred))

subset_pred <- grepl("beta1", dimnames(modelstuff[[1]])[[2]])
a["beta1"] <- median(get_values(modelstuff,subset_pred))

subset_pred <- grepl("scale", dimnames(modelstuff[[1]])[[2]])
a["scale"] <- median(get_values(modelstuff,subset_pred))
size <- seq(-2,4,length.out = 140)

# subset_pred <- grepl("y\\[", dimnames(lognorm_mcmc_rep[[1]])[[2]])
# mcmc_subset_y <- get_values(lognorm_mcmc_rep,subset_pred)

size <- seq(-2,4,length.out = 140)
#group 2 beta 2 is the group
scale_1 <- exp(a1["beta0"]+a1["beta1"]*size + a1["beta2"]*0)
scale_2 <- exp(a1["beta0"]+a1["beta1"]*size + a1["beta2"]*1)
shape <- 1/a1["scale"]
gr1_low <- qweibull(0.025,shape,scale_1)
gr1_mid <- qweibull(0.5,shape,scale_1)
gr1_up <- qweibull(0.975,shape,scale_1)
gr2_low <- qweibull(0.025,shape,scale_2)
gr2_mid <- qweibull(0.5,shape,scale_2)
gr2_up <- qweibull(0.975,shape,scale_2)
# 

# y_sample <- apply(mcmc_subset,2,mean)
# Grub$grubsize, Grub$value
# Grub2$grubsize, y_sample
plot(Grub$grubsize, Grub$value,  pch = 19,ylim = c(0,20), col = (Grub2$group + 2), lwd = 1.5,
      xlab = "Days", cex.lab = 1.8,
     ylab = "Overall survival probability")
lines(size,gr1_low, col = 2,lty = 2, lwd = 3)
lines(size,gr1_mid, col = 2, lwd = 3)
lines(size,gr1_up, col = 2,lty = 2, lwd = 3)
lines(size,gr2_low, col = 3,lty = 2, lwd = 3)
lines(size,gr2_mid, col = 3, lwd = 3)
lines(size,gr2_up, col = 3, lwd = 3,lty = 2)
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")


dev.off()
```
##### Sensitivity
```{r}
source("Bayes1_weibull_jags_sens.R")

```


```{r}
weibull$summaries[,4]
weibull_sens$summaries[,4]
weibull_sens2$summaries[,4]
```

## Without censored with random effects
### Lognormal
#### Models are calculated

```{r echo=F}
source("Bayes1_lognormal_Random_jags.R")
```

#### Results 

```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
summary(lognorm_rand_mcmc)
summary(lognorm_rand)

plot(lognorm_rand)
print(lognorm_rand)
plot(lognorm_rand_mcmc)


```


#### Diagnostics
##### Convergence checks
First Gelman and Rubin and Geweke Plots are created, therefore we also use coda but that is just a side note.
```{r}
print("gelman diag")
gelman.diag(lognorm_rand_mcmc, confidence = 0.95)
gelman.plot(lognorm_rand_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(lognorm_rand_mcmc)
geweke.plot(lognorm_rand_mcmc)
```

##### DIC

```{r}
extract.runjags(lognorm_rand, "dic")
```
##### DIC Manual
```{r}
subset_pred <- grepl("Deviance", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
md <- mean(mcmc_subset)

a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(lognorm_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(lognorm_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(lognorm_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
a["tau"] <- mean(get_values(lognorm_rand_mcmc_rep,subset_pred))
a1 <- a

subset_pred <- grepl("b0\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
b0_subset1 <- apply(get_values(lognorm_rand_mcmc_rep,subset_pred),2,mean)
b0_subset <- b0_subset1[Grub$id]

Grub$sim_value <- Grub$value

pd <- md - (-2 *sum(log(dlnorm(Grub$sim_value,a["beta0"]+a["beta1"]*Grub$grubsize 
                   + a["beta2"]*Grub$group + b0_subset,sqrt(1/a["tau"])))))

c(pd,md,pd+md)

```

##### Clustering of repsonses

```{r}
subset_pred <- grepl("b0\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
#Mean variance of the random effect:
mean(apply(mcmc_subset,1,var))
hist(mcmc_subset)
hist(apply(mcmc_subset,2,mean),breaks = 15)
#Mean variance of an estimaed random Effect
mean(apply(mcmc_subset,2,var))

```

##### CPO and PPo
CPO or better say the inverse of it
 

```{r}
subset_pred <- grepl("ppo\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

barplot(icpo)
plot(ippo)
#which y are thebiggest
matrix(order(icpo,decreasing = T),ncol = 14, nrow = 10, byrow = T)
#Table 2 
matrix(order(ippo,decreasing = T),ncol = 14, nrow = 10, byrow = T)

LPLM <- mean(log(cpo))
LPLM


```

```{r}
subset_pred <- grepl("ppo2\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

barplot(icpo)
plot(ippo)
#which y are thebiggest
matrix(order(icpo,decreasing = T),ncol = 14, nrow = 10, byrow = T)
#Table 2 
matrix(order(ippo,decreasing = T),ncol = 14, nrow = 10, byrow = T)

LPLM <- mean(log(cpo))
LPLM


```

##### PPC and more summary
 
```{r}

# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)

# p values not interpretable since not all observation even "have the abbility" to be so extreme, so it is even more
# frightening to find so big differences. This is probably not the best use of PPC in the case that every observations, basically has a different distribution 

mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

# how extreme is the CPO compared to the original one
# cpo in the repeated case is much smaller than in the former case
subset_pred <- grepl("ppo_rep\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
biggest_rep <- abs(1/apply(as.matrix(mcmc_subset),2,mean))
plot(biggest_rep)
print(as.vector(order(biggest_rep,decreasing = T)))
print("")

sort(biggest_rep, decreasing = T)[1:3]

```
##### PPC Random Effect Intercept

```{r}
#Non of the tests has crazy results
mean(get_values(lognorm_rand_mcmc_rep,"tmax.test"))
mean(get_values(lognorm_rand_mcmc_rep,"tmin.test"))
mean(get_values(lognorm_rand_mcmc_rep,"ks.test"))
mean(get_values(lognorm_rand_mcmc_rep,"ss.test"))

```
####Sensitivity Analysis
We set up t-distributed random effects
```{r  echo=F}
source("Bayes1_lognormal_Random_student_t_jags.R")

```

```{r}
#plot(lognorm_rand_student_t)
subset_pred <- grepl("b0\\[", dimnames(lognorm_rand_student_t_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_student_t_mcmc_rep,subset_pred)
subset_pred_sigma <- grepl("sigma_b0", dimnames(lognorm_rand_student_t_mcmc_rep[[1]])[[2]])
mcmc_subset_sigma <- get_values(lognorm_rand_student_t_mcmc_rep,subset_pred_sigma)
sigma_b0_mean <- mean(mcmc_subset_sigma)
b0_mean <- apply(mcmc_subset,2,mean)
normalized_b0 <- b0_mean/sigma_b0_mean
qqplot(qt(ppoints(20),4),normalized_b0)
qqline(normalized_b0,distribution = function(x) qt(x,4), probs = c(0.05,0.95))


#Mean variance of the random effect:
mean(apply(mcmc_subset,1,var))
hist(mcmc_subset)
hist(apply(mcmc_subset,2,mean),breaks = 15)
#Mean variance of an estimaed random Effect
mean(apply(mcmc_subset,2,var))

```


```{r}

#Non of the tests has crazy results
mean(get_values(lognorm_rand_student_t_mcmc_rep,"tmax.test"))
mean(get_values(lognorm_rand_student_t_mcmc_rep,"tmin.test"))
mean(get_values(lognorm_rand_student_t_mcmc_rep,"ks.test"))
mean(get_values(lognorm_rand_student_t_mcmc_rep,"ss.test"))

```
##### Changing Priors
```{r}
source("Bayes1_lognormal_Random_jags_sens.r")
```
```{r}
cat("\nModel2\n")
summary(lognorm_rand_sens2)
dic2
cat("\nModel3\n")
summary(lognorm_rand_sens3)
dic3
cat("\nModel1\n")
summary(lognorm_rand_sens1)
dic1
cat("\nModel4\n")
summary(lognorm_rand_sens4)
dic4
cat("\nModel5\n")
summary(lognorm_rand_sens5)
dic5
cat("\nModel6\n")
summary(lognorm_rand_sens6)
dic6
cat("\nModel7\n")
summary(lognorm_rand_sens7)
dic7
```


  ### Weibull

```{r  echo=F}
source("Bayes1_Weibull_Random_jags.R")

```

#### Results 

```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
summary(weibull_rand_mcmc)
summary(weibull_rand)

plot(weibull_rand)
cat("second kind of the plots seen before")
plot(weibull_rand_mcmc)
```
#### Diagnostics
##### Convergence checks
```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
weibull_rand_mcmc <- as.mcmc.list(weibull_rand)

print("gelman diag")
gelman.diag(weibull_rand_mcmc, confidence = 0.95)
gelman.plot(weibull_rand_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(weibull_rand_mcmc)
geweke.plot(weibull_rand_mcmc)
```

##### DIC

```{r}
extract.runjags(weibull_rand, "dic")
```


##### CPO and PPo
CPO or better say the inverse of it
```{r}
subset_pred <- grepl("ppo\\[", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_rand_mcmc_rep,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)
#which y are thebiggest
matrix(order(icpo,decreasing = T),ncol = 14, nrow = 10, byrow = T)
#Table 2 
matrix(order(ippo,decreasing = T),ncol = 14, nrow = 10, byrow = T)

LPLM <- mean(log(cpo))
LPLM
#Again some pseudo bayes factor
exp(-2.164256--2.237081)
```

##### PPC and more summary
 
```{r}


# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_rand_mcmc_rep,subset_pred)

#how do the simulated values look like
mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

# how extreme is the CPO compared to the original one
subset_pred <- grepl("ppo_rep\\[", dimnames(lognorm_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_mcmc_rep,subset_pred)
biggest_rep <- abs(1/apply(as.matrix(mcmc_subset),2,mean))
plot(biggest_rep)
print(as.vector(order(biggest_rep,decreasing = T)))
print("")

sort(biggest_rep, decreasing = T)[1:3]




```

##### PPC Random Effect Intercept

```{r}
# Distribution of the random effects checks
mean(get_values(weibull_rand_mcmc_rep,"tmax.test"))
mean(get_values(weibull_rand_mcmc_rep,"tmin.test"))
mean(get_values(weibull_rand_mcmc_rep,"ks.test"))
mean(get_values(weibull_rand_mcmc_rep,"ss.test"))



#
subset_pred <- grepl("b0\\[", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_rand_mcmc_rep,subset_pred)

hist(apply(as.matrix(mcmc_subset),2,mean), breaks = 10)
hist(apply(as.matrix(mcmc_subset),2,mean))
hist(mcmc_subset, breaks = 20)

```


##### DIC Manual
Again just for comparison. 
```{r}

#calculate md
subset_pred <- grepl("Deviance", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_rand_mcmc_rep,subset_pred)
mcmc_subset_dic<- mcmc_subset
md <- mean(mcmc_subset_dic)

# this version is super slow
# #calculate pd
# a <- summary(weibull_rep)
# a1 <- a[c("beta0","beta1","beta2","scale"),"Mean"]
a <- vector()
subset_pred <- grepl("beta0", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(weibull_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(weibull_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(weibull_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("scale", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
a["scale"] <- mean(get_values(weibull_rand_mcmc_rep,subset_pred))
a1 <- a

subset_pred <- grepl("b0\\[", dimnames(weibull_rand_mcmc_rep[[1]])[[2]])
b0_subset1 <- apply(get_values(weibull_rand_mcmc_rep,subset_pred),2,mean)
#b0_subset1 <- get_values(weibull_rand_mcmc_rep,subset_pred)[728,]
#since we reordered the ids initially since from small to big sorted
b0_subset <- b0_subset1[Grub$id]
#now we can use this values for comparison
scale <- exp(a1["beta0"]+a1["beta1"]*Grub$grubsize + a1["beta2"]*Grub$group +b0_subset)
shape <- 1/a1["scale"]

pd <- md - -2*sum(dweibull(Grub$value, scale = scale, shape  = shape, log = T))
pv <- var(mcmc_subset_dic)/2
c(pd,md,pd+md)
c(pv,md,pv+md)

```


## With censored without random effects
### Lognormal
#### Models are calculated
For further insides take a look on the code for the models

```{r echo=F}
source("Bayes1_lognormal_jags_censored.R")
```

```{r}
library(dplyr)
Grub2 <- read.csv("..\\data\\Grubs_Easy_normalized_size.csv")
Grub2$number <- 1:nrow(Grub)
Grub2 <- Grub2 %>% arrange(upperlim)
```
#### Results 

```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
mcmc_lognorm_cens <- as.mcmc.list(lognorm_cens)

summary(mcmc_lognorm_cens)
summary(lognorm_cens)

plot(lognorm_cens)
print(lognorm_cens)
 
cat("second kind of the plots seen before")
plot(mcmc_lognorm_cens)

```


#### Diagnostics
##### Convergence checks

```{r}
print("gelman diag")
gelman.diag(mcmc_lognorm_cens, confidence = 0.95)
gelman.plot(mcmc_lognorm_cens, confidence = 0.95)
print("geweke diag")
geweke.diag(mcmc_lognorm_cens)
geweke.plot(mcmc_lognorm_cens)
```

##### DIC
This one is now manually calculated, I am not sure if this way is completly write. 
```{r}

# a <- summary(lognorm_cens_rep)
# a <- a[c("beta0","beta1","beta2","sigma"),"Mean"]
#get all the means of the parameters this is in the calculation of the DIc used look in the formula if there are questions

subset_pred <- grepl("Deviance", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(lognorm_cens_rep_mcmc,subset_pred)
mcmc_subset_dic<- mcmc_subset
md <- mean(mcmc_subset_dic)

a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta0"] <- mean(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta2"] <- mean(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta1"] <- mean(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["tau"] <- mean(get_values(lognorm_cens_rep_mcmc,subset_pred))


#there is no real y value therefore again use the simulated ones
subset_pred <- grepl("y\\[", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(lognorm_cens_rep_mcmc,subset_pred)
Grub$sim_value <- apply(mcmc_subset,2,mean)
#now we cann use this values for comparison
pd <- md - (-2 *sum(log(dlnorm(Grub$sim_value,a["beta0"]+a["beta1"]*Grub$grubsize 
                   + a["beta2"]*Grub$group,sqrt(1/a["tau"])))))
pv <- var(mcmc_subset_dic)/2
c(pd,md,pd+md)
c(pv,md,pv+md)

```
##### CPO and PPo
CPO or better say the inverse of it
 

```{r}
subset_pred <- grepl("ppo\\[", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(lognorm_cens_rep_mcmc,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)


Grub2$number[order(icpo,decreasing = T)][1:7]
Grub2$number[order(ippo,decreasing = T)][1:7]

LPLM <- mean(log(cpo))
LPLM
#2.) extract the res values 
subset_pred <- grepl("res\\[", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(lognorm_cens_rep_mcmc,subset_pred)
#how look the average residuals in the log world?
hist(apply(mcmc_subset,2,mean), breaks = 20)
#pseudo bayes faktor hard coded ^^
exp(-2.504187--2.507666)
```

##### PPC and more summary
```{r}
 subset_pred <- grepl("y_rep\\[", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(lognorm_cens_rep_mcmc,subset_pred)

# # mcmc_subset
# #how often are the values bigger or smallen than the predicted ones
# max(apply(apply(mcmc_subset,1,function(x){x > Grub$value}),2,mean))
# 
# #how do the distribution look like comapred to the origninal one
# summary(mcmc_subset[,1])
# hist(Grub$value)
# hist(mcmc_subset[1,],breaks = 20)

# how extreme are the predicted values compared to the original ones
#this is basically generated y values with the same distribution as the true y values  
mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))
```

##### Plot the Model
```{r}

Grub2 <- read.csv("..\\data\\Grubs_Easy_normalized_size.csv")
Grub2$number <- 1:nrow(Grub)
Grub2 <- Grub2 %>% arrange(upperlim)

a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta0"] <- median(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta2"] <- median(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["beta1"] <- median(get_values(lognorm_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
a["tau"] <- median(get_values(lognorm_cens_rep_mcmc,subset_pred))


subset_pred <- grepl("y\\[", dimnames(lognorm_cens_rep_mcmc[[1]])[[2]])
mcmc_subset_y <- get_values(lognorm_cens_rep_mcmc,subset_pred)
y_sample <- apply(mcmc_subset_y,2,mean)


#group 2 beta 2 is the group
gr1_low <- qlnorm(0.025,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr1_mid <- qlnorm(0.5,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr1_up <- qlnorm(0.975,a["beta0"]+a["beta1"]*size + a["beta2"]*0,sqrt(1/a["tau"]))
gr2_low <- qlnorm(0.025,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
gr2_mid <- qlnorm(0.5,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
gr2_up <- qlnorm(0.975,a["beta0"]+a["beta1"]*size + a["beta2"]*1,sqrt(1/a["tau"]))
size <- seq(-2,4,length.out = 140)
# 


# Grub$grubsize, Grub$value
# Grub2$grubsize, y_sample
plot(Grub2$grubsize, y_sample,  pch = 19,ylim = c(0,20), col = (Grub2$group + 2), lwd = 1.5,
      xlab = "Days", cex.lab = 1.8,
     ylab = "Overall survival probability")
lines(size,gr1_low, col = 2,lty = 2, lwd = 3)
lines(size,gr1_mid, col = 2, lwd = 3)
lines(size,gr1_up, col = 2,lty = 2, lwd = 3)
lines(size,gr2_low, col = 3,lty = 2, lwd = 3)
lines(size,gr2_mid, col = 3, lwd = 3)
lines(size,gr2_up, col = 3, lwd = 3,lty = 2)
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")


pdf("..\\graphics\\Plot4.pdf", width = 7, height = 5)
plot(Grub2$grubsize, y_sample,  pch = 19,ylim = c(0,20), col = (Grub2$group + 2), lwd = 1.5,
      xlab = "Days", cex.lab = 1.4,
     ylab = "Overall survival probability")
lines(size,gr1_low, col = 2,lty = 2, lwd = 3)
lines(size,gr1_mid, col = 2, lwd = 3)
lines(size,gr1_up, col = 2,lty = 2, lwd = 3)
lines(size,gr2_low, col = 3,lty = 2, lwd = 3)
lines(size,gr2_mid, col = 3, lwd = 3)
lines(size,gr2_up, col = 3, lwd = 3,lty = 2)
legend("topright", legend = c("SS", "HB"),lwd = 3,
               lty = 1,col = c(2,3),
               title = "Groups")
dev.off()
```
### Weibull

```{r  echo=F}
source("Bayes1_Weibull_cens_jags.R")
```


#### Results 

```{r}

summary(weibull_cens_mcmc)
summary(weibull_cens)

plot(weibull_cens)
 

cat("second kind of the plots seen before")
plot(weibull_cens_mcmc)


```
#### Diagnostics
##### Convergence checks
```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
weibull_cens_mcmc <- as.mcmc.list(weibull_cens)

print("gelman diag")
gelman.diag(weibull_cens_mcmc, confidence = 0.95)
gelman.plot(weibull_cens_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(weibull_cens_mcmc)
geweke.plot(weibull_cens_mcmc)
```

##### DIC

```{r}
# 
# a <- summary(weibull_cens_rep_mcmc)
# a1 <- a$statistics[c("beta0","beta1","beta2","scale"),"Mean"]
subset_pred <- grepl("Deviance", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rep_mcmc,subset_pred)
md <- mean(mcmc_subset)
pv <- var(mcmc_subset)/2

a <- vector()
subset_pred <- grepl("beta0", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
a["beta0"] <- mean(get_values(weibull_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta2", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
a["beta2"] <- mean(get_values(weibull_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("beta1", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
a["beta1"] <- mean(get_values(weibull_cens_rep_mcmc,subset_pred))

subset_pred <- grepl("scale", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
a["scale"] <- mean(get_values(weibull_cens_rep_mcmc,subset_pred))
a1 <- a

#there is no real y value therefore again use the simulated ones and their mean, may be first always calculate DIC and then
#use mean implement also if there is still time. But this for of calculation makes more sense for me right now, since if we do something with the model we would often use the mean. But the other one ofc makes also quite some sense

subset_pred <- grepl("y\\[", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rep_mcmc,subset_pred)
Grub$sim_value <- apply(mcmc_subset,2,mean)
#now we can use this values for comparison
scale <- exp(a1["beta0"]+a1["beta1"]*Grub$grubsize + a1["beta2"]*Grub$group)
#for exampe see weibull_baysian_easy (i know wrong spelling ^^) exp()
shape <- 1/a1["scale"]
pd <- md - -2*sum(dweibull(Grub$sim_value, scale = scale, shape  = shape, log = T))

c(pd,md,pd+md)

c(pv,md,pv+md)

```
##### CPO and PPo

```{r}
subset_pred <- grepl("ppo\\[", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rep_mcmc,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)


Grub2$number[order(icpo,decreasing = T)][1:7]
Grub2$number[order(ippo,decreasing = T)][1:7]
#b0_subset1[Grub$id]

LPLM <- mean(log(cpo))
LPLM
```

##### PPC and more summary
 
```{r}
# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rep_mcmc,subset_pred)

# p values not interpretable since not all observation even "have the abbility" to be so extreme, so it is even more
# frightening to find so big differences. This is probably not the best use of PPC in the case that every observations, basically has a different distribution 

mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

# # how extreme is the CPO compared to the original one
# # cpo in the repeated case is much smaller than in the former case
# subset_pred <- grepl("ppo_rep\\[", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
# mcmc_subset <- get_values(weibull_cens_rep_mcmc,subset_pred)
# biggest_rep <- abs(1/apply(as.matrix(mcmc_subset),2,mean))
# plot(biggest_rep)
# order(biggest_rep,decreasing = T)
# sort(biggest_rep, decreasing = T)[1:3]
# Grub$id[c(106,43,131)]




```

## with censored with random effects
### Lognormal
#### Models are calculated

```{r echo=F}
source("Bayes1_lognormal_cens_Random_jags.R")
```
#### Results 

```{r}
summary(lognorm_rand_cens_mcmc)
summary(lognorm_rand_cens)
plot(lognorm_rand_cens)
print(lognorm_rand_cens)
 

cat("second kind of the plots seen before")
plot(lognorm_rand_cens_mcmc)
```


#### Diagnostics
##### Convergence checks
First Gelman and Rubin and Geweke Plots are created, therefore we also use coda but that is just a side note.
```{r}
print("gelman diag")
gelman.diag(lognorm_rand_cens_mcmc, confidence = 0.95)
gelman.plot(lognorm_rand_cens_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(lognorm_rand_cens_mcmc)
geweke.plot(lognorm_rand_cens_mcmc)
```

##### DIC
```{r}
subset_pred <- grepl("Deviance", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_cens_mcmc_rep,subset_pred)
md <- mean(mcmc_subset)

a <- vector()
subset_pred <- grepl("beta0", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(lognorm_rand_cens_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(lognorm_rand_cens_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(lognorm_rand_cens_mcmc_rep,subset_pred))

subset_pred <- grepl("tau", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
a["tau"] <- mean(get_values(lognorm_rand_cens_mcmc_rep,subset_pred))
a1 <- a

subset_pred <- grepl("b0\\[", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
b0_subset1 <- apply(get_values(lognorm_rand_cens_mcmc_rep,subset_pred),2,mean)
#since we reordered the ids initially since from small to big sorted
b0_subset <- b0_subset1[Grub$id]

#there is no real y value therefore again use the simulated ones and their mean, may be first always calculate DIC and then
#use mean implement also if there is still time. But this for of calculation makes more sense for me right now, since if we do something with the model we would often use the mean. But the other one ofc makes also quite some sense
subset_pred <- grepl("y\\[", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
mcmc_subset_y <- get_values(lognorm_rand_cens_mcmc_rep,subset_pred)

Grub$sim_value <- apply(mcmc_subset_y,2,mean)

pd <- md - (-2 *sum(log(dlnorm(Grub$sim_value,a["beta0"]+a["beta1"]*Grub$grubsize 
                   + a["beta2"]*Grub$group + b0_subset,sqrt(1/a["tau"])))))

c(pd,md,pd+md)

lognorm_dic(lognorm_rand_cens_mcmc_rep)
```

##### CPO and PPo
CPO or better say the inverse of it

```{r}
subset_pred <- grepl("ppo\\[", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_cens_mcmc_rep,subset_pred)
#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)


Grub2$number[order(icpo,decreasing = T)][1:7]
Grub2$number[order(ippo,decreasing = T)][1:7]
LPLM <- mean(log(cpo))
LPLM

```

##### PPC and more summary
 
```{r}

# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_cens_mcmc_rep,subset_pred)

# p values not interpretable since not all observation even "have the abbility" to be so extreme, so it is even more
# frightening to find so big differences. This is probably not the best use of PPC in the case that every observations, basically has a different distribution 

mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

# how extreme is the CPO compared to the original one
# cpo in the repeated case is much smaller than in the former case
subset_pred <- grepl("ppo_rep\\[", dimnames(lognorm_rand_cens_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_cens_mcmc_rep,subset_pred)
biggest_rep <- abs(1/apply(as.matrix(mcmc_subset),2,mean))
plot(biggest_rep)
print(as.vector(order(biggest_rep,decreasing = T)))
print("")

sort(biggest_rep, decreasing = T)[1:3]
```
##### PPC Random Effect Intercept

```{r}
mean(get_values(lognorm_rand_cens_mcmc_rep,"tmax.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep,"tmin.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep,"ks.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep,"ss.test"))

```

####Sensitivity analysis

We set up t-distributed random effects
```{r  echo=F}
source("Bayes1_lognormal_cens_Random_jags_student_t.R")

```

```{r}
#plot(lognorm_rand_student_t)
subset_pred <- grepl("b0\\[", dimnames(lognorm_rand_cens_mcmc_rep_student_t[[1]])[[2]])
mcmc_subset <- get_values(lognorm_rand_cens_mcmc_rep_student_t,subset_pred)
subset_pred_sigma <- grepl("sigma_b0", dimnames(lognorm_rand_cens_mcmc_rep_student_t[[1]])[[2]])
mcmc_subset_sigma <- get_values(lognorm_rand_cens_mcmc_rep_student_t,subset_pred_sigma)
sigma_b0_mean <- mean(mcmc_subset_sigma)
b0_mean <- apply(mcmc_subset,2,mean)
normalized_b0 <- b0_mean/sigma_b0_mean
# TQQPlot(normalized_b0,4)
# qqplot(qt(ppoints(20),4),normalized_b0)
# qqline(normalized_b0,distribution = function(x) qt(x,4), probs = c(0.05,0.95))


#Mean variance of the random effect:
mean(apply(mcmc_subset,1,var))
hist(mcmc_subset)
hist(apply(mcmc_subset,2,mean),breaks = 15)
#Mean variance of an estimaed random Effect
mean(apply(mcmc_subset,2,var))
```

```{r}
#Non of the tests has crazy results
mean(get_values(lognorm_rand_cens_mcmc_rep_student_t,"tmax.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep_student_t,"tmin.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep_student_t,"ks.test"))
mean(get_values(lognorm_rand_cens_mcmc_rep_student_t,"ss.test"))

```
##### Changing Priors
```{r}
source("Bayes1_lognormal_Random_cens_sens_jags.R")
```
```{r}
#
# cat("the original estimations\n")
# dic2 = lognorm_dic(lognorm_rand_cens_mcmc_rep)
# add.summary(lognorm_rand_cens_rep, vars = c("beta0","beta1","beta2","sigma","b0[1]"))
#
cat("\n\nModel2 Bigger beta priors\n")
dic2 = lognorm_dic(lognorm_rand_cens_sens2)
add.summary(lognorm_rand_cens_sens2, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
#
cat("\n\nModel3 smaller beta priors\n")
add.summary(lognorm_rand_cens_sens3, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
dic3 = lognorm_dic(lognorm_rand_cens_sens3)
#
cat("\n\nModel1 Vary the Distribution of the sigma and random effect sigma\n")
add.summary(lognorm_rand_cens_sens1, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
dic1 = lognorm_dic(lognorm_rand_cens_sens1)
#
cat("\n\nModel4 Vary the Distribution of the sigma and random effect sigma\n")
add.summary(lognorm_rand_cens_sens4, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
dic4 = lognorm_dic(lognorm_rand_cens_sens4)
#
cat("\n\nModel5 Vary the Distribution of the random effect sigma\n")
add.summary(lognorm_rand_cens_sens5, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
dic5 = lognorm_dic(lognorm_rand_cens_sens5)
#
cat("\n\nModel6 Vary everything\n")
add.summary(lognorm_rand_cens_sens6, vars = c("beta0","beta1","beta2","sigma","tau","b0[1]"))
dic6 = lognorm_dic(lognorm_rand_cens_sens6)
#
cat("\n\nModel7 No Grubsize\n")
add.summary(lognorm_rand_cens_sens7, vars = c("beta0","beta2","sigma","tau","b0[1]"))
dic7 = lognorm_dic(lognorm_rand_cens_sens7)

```

### Weibull

```{r  echo=F}
source("Bayes1_Weibull_cens_Random_jags.R")
```

#### Results 

```{r}
weibull_cens_rand_mcmc <- as.mcmc.list(weibull_cens_rand)

summary(weibull_cens_rand_mcmc)
summary(weibull_cens_rand)
plot(weibull_cens_rand)
 
cat("second kind of the plots seen before")
plot(weibull_cens_rand_mcmc)

```
#### Diagnostics
##### Convergence checks
```{r}
#coda integration so also coda stuff is available
#Model Diagnostik plots
weibull_cens_rand_mcmc <- as.mcmc.list(weibull_cens_rand)

print("gelman diag")
gelman.diag(weibull_cens_rand_mcmc, confidence = 0.95)
gelman.plot(weibull_cens_rand_mcmc, confidence = 0.95)
print("geweke diag")
geweke.diag(weibull_cens_rand_mcmc)
geweke.plot(weibull_cens_rand_mcmc)
```

##### DIC

```{r}
subset_pred <- grepl("Deviance", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rand_mcmc_rep,subset_pred)
md <- mean(mcmc_subset)

a <- vector()
subset_pred <- grepl("beta0", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
a["beta0"] <- mean(get_values(weibull_cens_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta2", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
a["beta2"] <- mean(get_values(weibull_cens_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("beta1", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
a["beta1"] <- mean(get_values(weibull_cens_rand_mcmc_rep,subset_pred))

subset_pred <- grepl("scale", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
a["scale"] <- mean(get_values(weibull_cens_rand_mcmc_rep,subset_pred))
a1 <- a

subset_pred <- grepl("b0\\[", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
b0_subset1 <- apply(get_values(weibull_cens_rand_mcmc_rep,subset_pred),2,mean)
#since we reordered the ids initially since from small to big sorted
b0_subset <- b0_subset1[Grub$id]
#there is no real y value therefore again use the simulated ones and their mean, may be first always calculate DIC and then
#use mean implement also if there is still time. But this for of calculation makes more sense for me right now, since if we do something with the model we would often use the mean. But the other one ofc makes also quite some sense
subset_pred <- grepl("y\\[", dimnames(weibull_cens_rep_mcmc[[1]])[[2]])
mcmc_subset_y <- get_values(weibull_cens_rep_mcmc,subset_pred)

Grub$sim_value <- apply(mcmc_subset_y,2,mean)

#now we can use this values for comparison
#for exampe see weibull_baysian_easy (i know wrong spelling ^^) exp()
scale <- exp((a1["beta0"]+a1["beta1"]*Grub$grubsize + a1["beta2"]*Grub$group +b0_subset ))
shape <- 1/a1["scale"]

pd <- md - (-2*sum(dweibull(Grub$sim_value , scale = scale, shape  = shape, log = T)))

pv <- var(mcmc_subset)/2

c(pd,md,pd+md)
c(pv, md,pv+md)
```
#####Interpretation Weibull and Lognormal
```{r}
# qweibull(0.4,1,2)
# qweibull(0.4,1,2*1.02)/1.02

#Weibull Case
#if we have group 2 instead of group 1, we have have an increase of quantile survival time by ((exp(beta2)-1)*100)% (survival time changes by a factor of exp(beta2) beta2 symbolizes the group)
#((exp(a1["beta2"])-1)*100)
#in this case the expected survival time shrinks for 27%

#Lognormal Case
#if we have group 2 instead of group 1, we encounter an increase of a1["beta2"] in terms of the log value of the survival time and in terms of the the true survival time the change is the same as for the weibull case exp(beta2) ((exp(beta2)-1)*100)% 

```
##### CPO and PPo
CPO or better say the inverse of it
 

```{r}
subset_pred <- grepl("ppo\\[", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rand_mcmc_rep,subset_pred)

#cpo (leave one out Prediction)
cpo <- (apply(1/as.matrix(mcmc_subset),2,mean))^-1
icpo <- cpo^-1
#ppo (without leave one out, therefore violates liklihoodprinciple(dont predict with same data))
ppo <- (apply(as.matrix(mcmc_subset),2,mean))
ippo <- ppo^-1

plot(icpo)
plot(ippo)


Grub2$number[order(icpo,decreasing = T)][1:7]
Grub2$number[order(ippo,decreasing = T)][1:7]

LPLM <- mean(log(cpo))
LPLM
exp(-2.769448 + 2.442157)
```

##### PPC and more summary without random intercept
 
```{r}

# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rand_mcmc_rep,subset_pred)

# p values not interpretable since not all observation even "have the abbility" to be so extreme, so it is even more
# frightening to find so big differences. This is probably not the best use of PPC in the case that every observations, basically has a different distribution 

mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))

# how extreme is the CPO compared to the original one
# cpo in the repeated case is much smaller than in the former case
subset_pred <- grepl("ppo_rep\\[", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rand_mcmc_rep,subset_pred)
biggest_rep <- abs(1/apply(as.matrix(mcmc_subset),2,mean))
plot(biggest_rep)
order(biggest_rep,decreasing = T)
sort(biggest_rep, decreasing = T)[1:3]
Grub$id[c(35,133,119)]
```

##### PPC Random Effect Intercept

```{r}
# summary_weibull <- summary(weibull_cens_rand_mcmc_rep)
# b_params <- summary_weibull$statistics[grepl("b0\\[", dimnames(summary_weibull$statistics)[[1]]),]
#mean(b_params[1:10,1])
#attributes(summary_weibull$statistics)
#how unnormal the random effects
mean(get_values(weibull_cens_rand_mcmc_rep,"tmax.test"))
mean(get_values(weibull_cens_rand_mcmc_rep,"tmin.test"))
mean(get_values(weibull_cens_rand_mcmc_rep,"ks.test"))
mean(get_values(weibull_cens_rand_mcmc_rep,"ss.test"))


# how extreme are the predicted values compared to the original ones
subset_pred <- grepl("y_rep\\[", dimnames(weibull_cens_rand_mcmc_rep[[1]])[[2]])
mcmc_subset <- get_values(weibull_cens_rand_mcmc_rep,subset_pred)

# p values not interpretable since not all observation even "have the abbility" to be so extreme, so it is even more
# frightening to find so big differences. This is probably not the best use of PPC in the case that every observations, basically has a different distribution 

mean(apply(mcmc_subset,1,function(x){sum(x >= 12)  >= (sum(Grub$value >=12))}))
mean(apply(mcmc_subset,1,function(x){sum(x >= 6)  >= (sum(Grub$value >=6))}))
mean(apply(mcmc_subset,1,function(x){sum(x <= 2)  >= (sum(Grub$value <= 2))}))
```
#### Outlier stuff
105, 91, 126 are especially high in average
```{r}
Grub_outlier <- Grub2[Grub2$number %in% c(105,91,126),]
Grub2[Grub2$number %in% c(105,91,126),]
```
all outlier are in Group 2, they all survive the whole experiment but they are on different plates. Their size is not special at all. 

```{r}
Grub2[(Grub2$group == 1) &(Grub2$value == 12) ,]

```
All that have survived in the second group the 12 days, shoud not have happend, according to the distribution
```{r}
Grub2[(Grub2$group == 1) ,]

```

