mean(dnorm(0, mean = seq(0,1, by = 0.001) ,sd = 0.25))
mean(dnorm(0, mean = seq(-10,10, by = 0.001) ,sd = 0.25))
mean(dnorm(0, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
mean(dnorm(0, mean = seq(-100,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-100,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-1000,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-1,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-0.2,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
sum(dnorm(2, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
sum(dnorm(1, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
sum(dnorm(1, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
sum(dnorm(0, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
plot(z,sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
z <- seq(0,1, by = 0.001)
plot(z,sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
plot(z,sapply(z, p_steck_unten))
p_steck_unten <- function(z){
sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25))
}
plot(z,sapply(z, p_steck_unten))
plot(z,sapply(z, p_steck_unten), type = "l")
p_steck_oben <- function(z){
sum(dnorm(z, mean = seq(1,11, by = 0.001) ,sd = 0.25))
}
plot(z,sapply(z, p_steck_oben), type = "l")
plot(z,sapply(z, p_steck_unten)/p_steck_oben(0), type = "l")
plot(z,sapply(z, p_steck_unten)/(2*p_steck_unten(0)), type = "l")
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
}
#die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
return(steck_unten_approx(z)/ steck_unten_approx(0))
}
p_steck_unten(0)
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
}
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
}
#die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
p_steck_unten(0)
p_steck_unten(1)
p_steck_unten(0.3)
p_steck_unten(0.2)
p_steck_unten(0.1)
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.0001) ,sd = 0.25)))
}
#die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
p_steck_unten(0.1)
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.0001) ,sd = 0.1)))
}
#die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
p_steck_unten(0.1)
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.1)))
}
#die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
p_steck_unten(0.1)
p_steck_oben <- function(z){
steck_oben_approx <- function(z){
return(sum(dnorm(z, mean = seq(1,11, by = 0.001) ,sd = 0.25)))
}
return(steck_oben_approx(z)/ (steck_oben_approx(1)*2))
}
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten)/(2*p_steck_unten(0)), type = "l")
plot(z,sapply(z, p_steck_oben), type = "l")
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten), type = "l")
mean(dnorm(1, mean = seq(0,1, by = 0.001) ,sd = 0.25))
mean(dnorm(1, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(1, mean = seq(0,1, by = 0.00001) ,sd = 0.25))
mean(dnorm(0.5, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(1, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(0, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(0, mean = seq(0,1, by = 0.000001) ,sd = 0.25))
mean(dnorm(0, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(0, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(0.5, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
pnorm(0.5)
pnorm(mean = 0.5, sd = 0.25)
pnorm(0, mean = 0.5, sd = 0.025)
pnorm(0, mean = 0.5, sd = 0.25)
1 - 2 * pnorm(0, mean = 0.5, sd = 0.25)
mean(dnorm(0.5, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
mean(dnorm(0, mean = seq(0,1, by = 0.0001) ,sd = 0.25))
pnorm(0, mean = 4, sd = 4)
pnorm(0, mean = 4, sd = 1)
pnorm(0, mean = 4, sd = 1) + pnorm(4, mean = 4, sd = 1)
plot(z,mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
plot(z,mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
#logisches Ergebnis, da ist quasi die Frage, was ist die durchschnitt
#liche dichte der einzelnen Verteilungsfunktionen. Da wir auf 0,1 arbeiten
# mit einer geringen sd. Ist für den mittelsten Wert die durcschnittliche Dichte
# ungefähr 0.95, da symetrische Wahrscheinlichkeit und das dann die FLäche
p_getroffen <- function(z){
return(mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
}
p_getroffen(0)
p_getroffen(2)
p_getroffen(1)
plot(z,sapply(z, p_getroffen), type = "l")
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten), type = "l")
plot(z,sapply(z, p_steck_oben), type = "l")
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
z <- seq(0,1, by = 0.01)
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
p_steck_unten(0.4)
p_steck_oben(0.6)
p_steck_unten(0.1)
p_steck_oben(0.9)
p_steck_unten <- function(z){
return(p_steck_oben(1 - z))
}
p_steck_unten(0.1)
p_steck_oben(0.9)
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten), type = "l")
plot(z,sapply(z, p_steck_oben), type = "l")
#logisches Ergebnis, da ist quasi die Frage, was ist die durchschnitt
#liche dichte der einzelnen Verteilungsfunktionen. Da wir auf 0,1 arbeiten
# mit einer geringen sd. Ist für den mittelsten Wert die durcschnittliche Dichte
# ungefähr 0.95, da symetrische Wahrscheinlichkeit und das dann die FLäche
p_getroffen <- function(z){
return(mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
}
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
}
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
p_steck_oben <- function(z){
return(p_steck_unten(1 - z))
}
p_steck_unten(0.1)
p_steck_oben(0.9)
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten), type = "l")
plot(z,sapply(z, p_steck_oben), type = "l")
#logisches Ergebnis, da ist quasi die Frage, was ist die durchschnitt
#liche dichte der einzelnen Verteilungsfunktionen. Da wir auf 0,1 arbeiten
# mit einer geringen sd. Ist für den mittelsten Wert die durcschnittliche Dichte
# ungefähr 0.95, da symetrische Wahrscheinlichkeit und das dann die FLäche
p_getroffen <- function(z){
return(mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
}
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
a <-  p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten)
a <-  sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten)
a
source('C:/Valentin/Goettingen/3_Semester/Baysian_2/Metropolis.R', encoding = 'UTF-8')
a
# #die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# # 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
p_steck_oben <- function(z){
steck_oben_approx <- function(z){
return(sum(dnorm(z, mean = seq(1,11, by = 0.001) ,sd = 0.25)))
}
return(steck_oben_approx(z)/ (steck_oben_approx(1)*2))
}
a <-  sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten)
a
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
p_steck_unten(0.1)
p_steck_oben(0.9)
p_steck_unten <- function(z){
steck_unten_approx <- function(z){
return(sum(dnorm(z, mean = seq(-10,0, by = 0.001) ,sd = 0.25)))
}
return(steck_unten_approx(z)/ (steck_unten_approx(0)*2))
}
# #die Wahrscheinlichkeit auf Untenstecken für 0 (ist ja ungefähr
# # 0.5 da über 4 sd sehr unwahrscheinlich) normalisieren
p_steck_oben <- function(z){
steck_oben_approx <- function(z){
return(sum(dnorm(z, mean = seq(1,11, by = 0.001) ,sd = 0.25)))
}
return(steck_oben_approx(z)/ (steck_oben_approx(1)*2))
}
p_steck_unten(0.1)
p_steck_oben(0.9)
#normalisieren auf 0.5
plot(z,sapply(z, p_steck_unten), type = "l")
plot(z,sapply(z, p_steck_oben), type = "l")
#logisches Ergebnis, da ist quasi die Frage, was ist die durchschnitt
#liche dichte der einzelnen Verteilungsfunktionen. Da wir auf 0,1 arbeiten
# mit einer geringen sd. Ist für den mittelsten Wert die durcschnittliche Dichte
# ungefähr 0.95, da symetrische Wahrscheinlichkeit und das dann die FLäche
p_getroffen <- function(z){
return(mean(dnorm(z, mean = seq(0,1, by = 0.0001) ,sd = 0.25)))
}
plot(z,sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten) , type = "l")
a <-  sapply(z, p_getroffen) + sapply(z, p_steck_oben) + sapply(z, p_steck_unten)
a
.libpaths()
install.packages("repr")
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-49017,3147-155)
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-41017,3147-155)
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-51017,3147-155)
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-49017,3147-155)
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-51017,3147-155)
# cor(data_wide_model2[,7:18], use = "pairwise.complete.obs") %>%  round(3)
# cov(data[,1:12], use = "pairwise.complete.obs") %>%  round(1)
pchisq(52979-49017,52979-49017)
52979-49017
data_long$year0.5 <- ifelse(data_long$years_after == 0.5, 1,0)
library(lme4)
#lognormal Modell 1 no random effects
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(coda)
library(R2OpenBUGS)
Grub <- read.csv("..\\data\\Grubs_Easy_normalized_size.csv")
model.data <- list( y = (Grub$value), N = length(Grub$value), x1 = Grub$grubsize,
x2 = Grub$group)
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
W[i] <- dnorm(y[i],mu[i],sigma)
W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
# W[i] <- dnorm(y[i],mu[i],sigma)
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
W[i] <- dnorm(y[i],mu[i],sigma)
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
}
for (i in 1:N){
W[i] <- dnorm(y[i],mu[i],sigma)
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
}
for (i in 1:N){
W[i] <- qnorm(0.8,mu[i],sigma)
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
source('C:/Valentin/Goettingen/3_Semester/Baysian_2/Baysian_GitHUb/R_Code/helpfunctions.R')
source('C:/Valentin/Goettingen/3_Semester/Baysian_2/Baysian_GitHUb/R_Code/helpfunctions.R')
#lognormal Modell 1 no random effects
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(coda)
library(R2OpenBUGS)
Grub <- read.csv("..\\data\\Grubs_Easy_normalized_size.csv")
# Grub$grubsize <- scale(Grub$grubsize)
# attributes(Grub$grubsize) <- NULL
# # Grub$group <- scale(Grub$group)
model.data <- list( y = (Grub$value), N = length(Grub$value), x1 = Grub$grubsize,
x2 = Grub$group)
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
}
for (i in 1:N){
W[i] <- qnorm(0.8,mu[i],sigma)
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
# parameters = c("sigma", "beta2", "beta0", "beta1")
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
#####Results####
# MODEL SPECIFICATION
model.function <- function(){
for (i in 1:N){
y[i] ~ dnorm(mu[i], sigma)
predict[i] ~ dnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i] + beta2 *x2[i]
D[i] <- - log(sigma) + log(2*3.14159265358979) + pow(log(y[i])-mu[i],2)*sigma
}
for (i in 1:N){
ppo[i] <- dnorm(k[i],mu[i],sigma)
k[i] <- log(y[i])
#W2[i] <- log(W[i])
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.000001)
beta1 ~ dnorm(0,0.000001)
beta2 ~ dnorm(0,0.000001)
Deviance <- sum(D[])
# DTest <- sum(W2[])
}
write.model(model.function, "Scripts\\Bayes1_lognormal.txt")
model.inits <- function(){list(sigma=2, beta0=1, beta1 = 1,beta2 = 1, predict = c(rep(0,times = 140)))}
parameters = c("DTest","sigma", "beta2", "beta0", "beta1","predict","Deviance")
model.out <- bugs(model.data, model.inits,
model.file = "Bayes1_lognormal.txt",
parameters=parameters,
n.chains = 2, n.iter = 5000,  n.burnin = 0, debug = T,
codaPkg=T,
working.directory = ".\\Scripts")
#Testfile BIC
x <- runif(200,0,10)
#Testfile BIC
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
y <- x + rnorm(200,0,5)
set.seed(1341234234)
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
set.seed(1341234234)
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
set.seed(1341234234)
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
#Testfile BIC
source("helpfunctions.r")
library("runjags")
library("coda")
library("rjags")
set.seed(1341234234)
x <- runif(200,0,10)
y <- x + rnorm(200,0,5)
model.data <- list( y = y, N = length(y), x1 = x)
#DEFINE INTITIAL VALUES
model.inits <- list(list(sigma=2, beta0=1, beta1 = 1),
list(sigma=2, beta0=1, beta1 = 1)
)
#Monitored Variables
parameters <-c("beta0", "beta1", "sigma")
model.function <- "model{
for (i in 1:N){
y[i] ~ dlnorm(mu[i], sigma)
mu[i] <- beta0 + beta1 *x1[i]
}
#priors
sigma ~ dgamma(0.001, 0.001)
beta0 ~ dnorm(0,0.001)
beta1 ~ dnorm(0,0.001)
}"
runjags.options(method = "rjparallel")
#Set Up Model
#Generate MCMC SAMpls
Model_test <- run.jags(model = model.function,
monitor = parameters, data = model.data,
inits = model.inits, burnin = 2000,
sample = 5000, thin = 1, n.chains = 2)
